points(x = c(3, 3), y = c(3, 3.2), pch = 16, cex = 5, col = "blue")
points(x = c(2, 2), y = c(2, 2.2), pch = 16, cex = 5,
col = rgb(red = 0, blue = 1, green = 0, alpha = 0.5))
points(x = c(4,4), y = c(4, 4.2), pch = 16, cex = 5,
col = rgb(red = 0, blue = 0, green = 0, alpha = 0.5))
pres08 <- read.csv("Datasets/pres08.csv")
pres08$Dem <- pres08$Obama / (pres08$Obama + pres08$McCain)
pres08 <- read.csv("Datasets/pres08.csv")
pres08$Dem <- pres08$Obama / (pres08$Obama + pres08$McCain)
pres08Rep <- pres08$McCain / (pres08$Obama + pres08$McCain)
pres08 <- read.csv("Datasets/pres08.csv")
pres08$Dem <- pres08$Obama / (pres08$Obama + pres08$McCain)
pres08Rep <- pres08$McCain / (pres08$Obama + pres08$McCain)
## color ofor California
cal.color <- rgb(red = pres08$Rep[pres08$state == "CA"],
blue = pres08$Dem[pres08$state == "CA"],
green = 0)
pres08 <- read.csv("Datasets/pres08.csv")
pres08$Dem <- pres08$Obama / (pres08$Obama + pres08$McCain)
pres08Rep <- pres08$McCain / (pres08$Obama + pres08$McCain)
## color ofor California
cal.color <- rgb(red = pres08$Rep[pres08$state == "CA"],
blue = pres08$Dem[pres08$state == "CA"],
green = 0)
## California as a blue state
## fill 是为每一个州填充具体的颜色
map(database = "state", regions = "California", col = "blue", fill = TRUE)
## California as a purple state
map(database = "state", regions = "California", col = cal.color, fill = TRUE)
pres08 <- read.csv("Datasets/pres08.csv")
pres08$Dem <- pres08$Obama / (pres08$Obama + pres08$McCain)
pres08Rep <- pres08$McCain / (pres08$Obama + pres08$McCain)
## color ofor California
cal.color <- rgb(red = pres08$Rep[pres08$state == "CA"],
blue = pres08$Dem[pres08$state == "CA"],
green = 0)
## California as a blue state
## fill 是为每一个州填充具体的颜色
map(database = "state", regions = "California", col = "blue", fill = TRUE)
## California as a purple state
map(database = "state", regions = "California", col = cal.color, fill = TRUE)
pres08$Rep[pres08$state == "CA"]
pres08 <- read.csv("Datasets/pres08.csv")
pres08
pres08$Dem <- pres08$Obama / (pres08$Obama + pres08$McCain)
pres08Rep <- pres08$McCain / (pres08$Obama + pres08$McCain)
## color for California
cal.color <- rgb(red = pres08$Rep[pres08$state == "CA"],
blue = pres08$Dem[pres08$state == "CA"],
green = 0)
## California as a blue state
## fill 是为每一个州填充具体的颜色
map(database = "state", regions = "California", col = "blue", fill = TRUE)
## California as a purple state
map(database = "state", regions = "California", col = cal.color, fill = TRUE)
pres08 <- read.csv("Datasets/pres08.csv")
pres08$Dem <- pres08$Obama / (pres08$Obama + pres08$McCain)
pres08Rep <- pres08$McCain / (pres08$Obama + pres08$McCain)
pres08 <- read.csv("Datasets/pres08.csv")
pres08$Dem <- pres08$Obama / (pres08$Obama + pres08$McCain)
pres08Rep <- pres08$McCain / (pres08$Obama + pres08$McCain)
(pres08$Obama + pres08$McCain
pres08 <- read.csv("Datasets/pres08.csv")
pres08$Dem <- pres08$Obama / (pres08$Obama + pres08$McCain)
pres08Rep <- pres08$McCain / (pres08$Obama + pres08$McCain)
pres08$Obama + pres08$McCain
pres08 <- read.csv("Datasets/pres08.csv")
pres08$Dem <- pres08$Obama / (pres08$Obama + pres08$McCain)
pres08Rep <- pres08$McCain / (pres08$Obama + pres08$McCain)
pres08$state
pres08 <- read.csv("Datasets/pres08.csv")
pres08$Dem <- pres08$Obama / (pres08$Obama + pres08$McCain)
pres08$Rep <- pres08$McCain / (pres08$Obama + pres08$McCain)
## color for California
cal.color <- rgb(red = pres08$Rep[pres08$state == "CA"],
blue = pres08$Dem[pres08$state == "CA"],
green = 0)
## California as a blue state
## fill 是为每一个州填充具体的颜色
map(database = "state", regions = "California", col = "blue", fill = TRUE)
## California as a purple state
map(database = "state", regions = "California", col = cal.color, fill = TRUE)
## USA as red and blue states
map(database = "state")
for(i in 1:nrow(pres08)){
if ((pres08$state[i] != "HI") & (pres08$state[i] != "AK") &
(pres08$state[i] != "DC")){
map(database = "state", regions = pres08$state.name[i],
col = ifelse(pres08$Rep[i] > pres08$Dem[i], "red", "blue"),
fill = TRUE, add = TRUE)
}
}
## USA as purple states
map(database = "state")
for(i in 1:nrow(pres08)){
if ((pres08$state[i] != "HI") & (pres08$state[i] != "AK") &
(pres08$state[i] != "DC")){
map(database = "state", regions = pres08$state.name[i],
col = rgb(red = pres08$Rep[i], blue = pres08$Dem[i], green = 0),
fill = TRUE, add = TRUE)
}
}
walmart <- read.csv("Datasets/walmart.csv")
walmart <- read.csv("Datasets/walmart.csv")
walmart$storecolors <- NA
walmart$storecolors[walmart$type == "Wal-MartStore"] <-
rgb(red = 1, green = 0, blue = 0, alpha = 1/3 )
walmart$storecolors[walmart$type == "SuperCenter"] <-
rgb(red = 0, green = 1, blue = 0, alpha = 1/3 )
walmart$storecolors[walmart$type == "DistributionCenter"] <-
rgb(red = 0, green = 0, blue = 1, alpha = 1/3 )
walmart$storesizes <- ifelse(walmart$type == "DistributionCenter", 1, 0.5)
walmart <- read.csv("Datasets/walmart.csv")
walmart$storecolors <- NA
walmart$storecolors[walmart$type == "Wal-MartStore"] <-
rgb(red = 1, green = 0, blue = 0, alpha = 1/3 )
walmart$storecolors[walmart$type == "SuperCenter"] <-
rgb(red = 0, green = 1, blue = 0, alpha = 1/3 )
walmart$storecolors[walmart$type == "DistributionCenter"] <-
rgb(red = 0, green = 0, blue = 1, alpha = 1/3 )
walmart$storesizes <- ifelse(walmart$type == "DistributionCenter", 1, 0.5)
## map with legend
map(database = "state")
points(walmart$long, walmart$lat, col = walmart$storecolors,
pch = 19, cex = walmart$storesizes)
legend(x = -120, y = 32, bty = "n",
legend = c("Walmart","Supercenter", "Distribution center"),
col = c("red", "green", "blue"), pch = 19,
pt.cex = c(0.5, 0.5, 1))
walmart.map <- function(data, date){
walmart <- subset(data, subset = (opendate <= date))
map(database = "state")
points(walmart$long, walmart$lat, col = walmart$storecolors,
pch = 19, cex = walmart$storesizes)
}
walmart.map <- function(data, date){
walmart <- subset(data, subset = (opendate <= date))
map(database = "state")
points(walmart$long, walmart$lat, col = walmart$storecolors,
pch = 19, cex = walmart$storesizes)
}
walmart$opendate <- as.Date(walmart$opendate)
walmart.map(walmart, as.Date("1974-12-31"))
walmart.map <- function(data, date){
walmart <- subset(data, subset = (opendate <= date))
map(database = "state")
points(walmart$long, walmart$lat, col = walmart$storecolors,
pch = 19, cex = walmart$storesizes)
}
walmart$opendate <- as.Date(walmart$opendate)
walmart.map(walmart, as.Date("1974-12-31"))
title("1975")
walmart.map(walmart, as.Date("1974-12-31"))
walmart.map <- function(data, date){
walmart <- subset(data, subset = (opendate <= date))
map(database = "state")
points(walmart$long, walmart$lat, col = walmart$storecolors,
pch = 19, cex = walmart$storesizes)
}
walmart$opendate <- as.Date(walmart$opendate)
walmart.map(walmart, as.Date("1974-12-31"))
title("1975")
walmart.map(walmart, as.Date("1984-12-31"))
title("1985")
walmart.map(walmart, as.Date("1994-12-31"))
title("1995")
walmart.map(walmart, as.Date("2004-12-31"))
title("2005")
install.packages("animation")
n <- 25
dates <- seq(from = min(walmart$opendate), to = max(walmart$opendate),
length.out = n)
library("animation")
saveHTML({
for(i in 1:length(dates)){
walmart.map(walmart, dates[i])
title(datas[i])
}
}, title = "Expansion of Walmart", htmlfile = "walmart.html", outdir = getwd(),
autobrowse = FALSE)
n <- 25
dates <- seq(from = min(walmart$opendate), to = max(walmart$opendate),
length.out = n)
library("animation")
saveHTML({
for(i in 1:length(dates)){
walmart.map(walmart, dates[i])
title(dates[i])
}
}, title = "Expansion of Walmart", htmlfile = "walmart.html", outdir = getwd(),
autobrowse = FALSE)
plot(florence, vertex.size = closeness(florence) * 1000,
main = "Closeness")
florence <- graph.adjacency(florence, mode = "undirected", diag = FALSE)
library("igraph")
florence <- graph.adjacency(florence, mode = "undirected", diag = FALSE)
florence <- graph.adjacency(florence, mode = "undirected", diag = FALSE)
florence <- read.csv("Datasets/florentine.csv", row.names = "FAMILY")
florence <- as.matrix(florence)
florence[1:5, 1:5]
rowSums(florence)
library("igraph")
florence <- graph.adjacency(florence, mode = "undirected", diag = FALSE)
plot(florence)
closeness(florence)
1 / (closeness(florence) * 15) ## 平均边数
betweenness(florence)
plot(florence, vertex.size = closeness(florence) * 1000, main = "Closeness")
## plot(florence, vertex.size = closeness(florence) * 1000, main = "Closeness")
plot(florence, vertex.size = betweenness(florence), main = "Betweenness")
plot(florence, vertex.size = closeness(florence), main = "Closeness")
# plot(florence, vertex.size = closeness(florence), main = "Closeness")
plot(florence, vertex.size = betweenness(florence), main = "Betweenness")
florence <- read.csv("Datasets/florentine.csv", row.names = "FAMILY")
florence <- as.matrix(florence)
florence[1:5, 1:5]
rowSums(florence)
library("igraph")
florence <- graph.adjacency(florence, mode = "undirected", diag = FALSE)
plot(florence)
degree(florence)
closeness(florence)
1 / (closeness(florence) * 15) ## 平均边数
betweenness(florence)
degree(florence)
closeness(florence)
1 / (closeness(florence) * 15) ## 平均边数
betweenness(florence)
degree(florence)
closeness(florence)
1 / (closeness(florence) * 15) ## 平均边数
betweenness(florence)
# plot(florence, vertex.size = closeness(florence), main = "Closeness")
plot(florence, vertex.size = betweenness(florence), main = "Betweenness")
plot(florence, vertex.size = closeness(florence), main = "Closeness")
# plot(florence, vertex.size = closeness(florence), main = "Closeness")
plot(florence, vertex.size = betweenness(florence), main = "Betweenness")
degree(florence)
closeness(florence)
1 / (closeness(florence) * 15) ## 平均边数
betweenness(florence)
library(tm, SnowballC)
## 导入数据
doc <- read.csv("Datasets/constitution.csv")
dim(doc)
head(doc)
docCorpus.raw <- Corpus( VectorSource(doc$preamble) )
control.list <- list(removePunctuation = TRUE, stopwords = TRUE, tolower = TRUE,
stripWhitespace = TRUE, stemDocument = TRUE)
doc.dtm <- DocumentTermMatrix(docCorpus.raw, control = control.list)
doc.dtm
inspect(doc.dtm[1:5, 1:8])
## 转化成标准矩阵
doc.dtm.mat <- as.matrix(doc.dtm)
## 计算逆文本频率
doc.tfidf <- weightTfIdf(doc.dtm)
## 转化为标准矩阵
doc.tfidf.mat <- as.matrix(doc.tfidf)
## 查看美国的位置
US <- subset(doc, doc$country == "united_states_of_america")
US
## 词云图
library(wordcloud)
wordcloud(colnames(doc.dtm.mat), doc.dtm.mat[149, ], max.word = 20)
wordcloud(colnames(doc.tfidf.mat), doc.tfidf.mat[149, ], max.word = 20)
wordcloud(colnames(doc.dtm.mat), doc.dtm.mat[149, ], max.word = 20)
wordcloud(colnames(doc.tfidf.mat), doc.tfidf.mat[149, ], max.word = 20)
sq <- rep(NA, 155)
for(i in 1:155){
a <- length(doc.tfidf.mat[i,])
sq[i] <- a ^2
}
a <- sqrt(sum(sq))
a
km <- kmeans(doc.tfidf / a, centers = 5)
km$iter
for ( i in 1:5){
cat("CLUSTER", i, "\n")
cat("Top 10 words: \n")
print(head(sort(km$centers[i, ], decreasing = TRUE), n = 10))
cat("\n")
print(rownames(doc.tfidf)[km$cluster == i])
cat("\n")
}
control.list <- list(removePunctuation = TRUE, stopwords = TRUE, tolower = TRUE,
stripWhitespace = TRUE, stemDocument = TRUE,removeNumbers = TRUE)
doc.dtm <- DocumentTermMatrix(docCorpus.raw, control = control.list)
doc.dtm
inspect(doc.dtm[1:5, 1:8])
## 转化成标准矩阵
doc.dtm.mat <- as.matrix(doc.dtm)
## 计算逆文本频率
doc.tfidf <- weightTfIdf(doc.dtm)
## 转化为标准矩阵
doc.tfidf.mat <- as.matrix(doc.tfidf)
## 查看美国的位置
US <- subset(doc, doc$country == "united_states_of_america")
US
## 词云图
library(wordcloud)
wordcloud(colnames(doc.dtm.mat), doc.dtm.mat[149, ], max.word = 20)
wordcloud(colnames(doc.tfidf.mat), doc.tfidf.mat[149, ], max.word = 20)
##### question 2  ######
sq <- rep(NA, 155)
for(i in 1:155){
a <- length(doc.tfidf.mat[i,])
sq[i] <- a ^2
}
a <- sqrt(sum(sq))
a
km <- kmeans(doc.tfidf / a, centers = 5)
km$iter
for ( i in 1:5){
cat("CLUSTER", i, "\n")
cat("Top 10 words: \n")
print(head(sort(km$centers[i, ], decreasing = TRUE), n = 10))
cat("\n")
print(rownames(doc.tfidf)[km$cluster == i])
cat("\n")
}
cosine <- function(a,b){
numer <- apply(a * t(b), 2, sum)
denom <- sqrt(sum(a ^2) * sqrt(apply(b^2, 1, sum)))
return(numer / denom)
}
doc$cosine <- cosine(doc.dtm.mat[155, ], doc.dtm.mat)
consine.order <- order(doc$cosine, decreasing =  TRUE)
doc[consine.order[1:5],]
##### question 4 #####
year <- seq(from = 1960, to = 2010, by = 10)
consine.mean <- rep(NA,length(year)-1)
for(i in 1:length(year)-1){
consine.mean[i] <- mean(doc$cosine[doc$year >= year[i] & doc$year < year[i+1]])
}
consine.mean
plot(year[-1], consine.mean,type = "l", col = "blue",
xlim = c(1970, 2010), ylim = c(0.5, 0.8),
xlab = "year", ylab = "consine")
n <- nrow(doc)
doc.mat <- matrix(0, nrow = n, ncol = n)
for ( i in 1:5){
cat("CLUSTER", i, "\n")
cat("Top 10 words: \n")
print(head(sort(km$centers[i, ], decreasing = TRUE), n = 10))
cat("\n")
print(rownames(doc.tfidf)[km$cluster == i])
cat("\n")
}
for ( i in 1:5){
cat("CLUSTER", i, "\n")
cat("Top 10 words: \n")
print(head(sort(km$centers[i, ], decreasing = TRUE), n = 10))
cat("\n")
}
cosine <- function(a,b){
numer <- apply(a * t(b), 2, sum)
denom <- sqrt(sum(a ^2) * sqrt(apply(b^2, 1, sum)))
return(numer / denom)
}
doc$cosine <- cosine(doc.dtm.mat[155, ], doc.dtm.mat)
consine.order <- order(doc$cosine, decreasing =  TRUE)
doc[consine.order[1:5],]
##### question 4 #####
year <- seq(from = 1960, to = 2010, by = 10)
consine.mean <- rep(NA,length(year)-1)
for(i in 1:length(year)-1){
consine.mean[i] <- mean(doc$cosine[doc$year >= year[i] & doc$year < year[i+1]])
}
consine.mean
plot(year[-1], consine.mean,type = "l", col = "blue",
xlim = c(1970, 2010), ylim = c(0.5, 0.8),
xlab = "year", ylab = "consine")
doc$cosine <- cosine(doc.dtm.mat[155, ], doc.dtm.mat)
consine.order <- order(doc$cosine, decreasing =  TRUE)
consine.order
consine.order <- doc[order(cosine, decreasing =  TRUE),]
consine.order <- doc[order(doc$cosine, decreasing =  TRUE),]
doc
doc$country[consine.order[1:5],]
consine.order <- order(doc$cosine, decreasing =  TRUE)
doc$country[consine.order[1:5],]
doc$country[doc$consine.order[1:5],]
doc$country[doc$consine.order[1:5]]
doc.cosine <- cosine(doc.dtm.mat[155, ], doc.dtm.mat)
sort(doc.cosine, decreasing = TRUE)[1:5]
doc.cosine <- cosine(doc.dtm.mat[rownames(dtm.mat) == "united_states_of_america", ], doc.dtm.mat)
doc.cosine <- cosine(doc.dtm.mat[rownames(doc.dtm.mat) == "united_states_of_america", ], doc.dtm.mat)
rownames(doc.dtm.mat)
doc.dtm.mat
doc.cosine <- cosine(doc.dtm.mat[155, ], doc.dtm.mat)
sort(doc.cosine, decreasing = TRUE)[1:5]
top5 <-  sort(doc.cosine, decreasing = TRUE)[1:5]
class(top5)
##### question 4 #####
year <- seq(from = 1960, to = 2010, by = 10)
row.names(top5)
##
## file :exercise1.R
## author: wxzher
## update: 2022-08-14
## the code for exercie1 in Chapter5
##
## 分析宪法的序言
###### question 1 ######
## load two required libraries
library(tm, SnowballC)
## 导入数据
doc <- read.csv("Datasets/constitution.csv")
dim(doc)
head(doc)
docCorpus.raw <- Corpus( VectorSource(doc$preamble) )
control.list <- list(removePunctuation = TRUE, stopwords = TRUE, tolower = TRUE,
stripWhitespace = TRUE, stemDocument = TRUE,removeNumbers = TRUE)
doc.dtm <- DocumentTermMatrix(docCorpus.raw, control = control.list)
inspect(doc.dtm[1:5, 1:8])
## 转化成标准矩阵
doc.dtm.mat <- as.matrix(doc.dtm)
## 计算逆文本频率
doc.tfidf <- weightTfIdf(doc.dtm)
## 转化为标准矩阵
doc.tfidf.mat <- as.matrix(doc.tfidf)
## 查看美国的位置
US <- subset(doc, doc$country == "united_states_of_america")
US
## 词云图
library(wordcloud)
wordcloud(colnames(doc.dtm.mat), doc.dtm.mat[149, ], max.word = 20)
wordcloud(colnames(doc.tfidf.mat), doc.tfidf.mat[149, ], max.word = 20)
##### question 2  ######
sq <- rep(NA, 155)
for(i in 1:155){
a <- length(doc.tfidf.mat[i,])
sq[i] <- a ^2
}
a <- sqrt(sum(sq))
a
km <- kmeans(doc.tfidf / a, centers = 5)
km$iter
for ( i in 1:5){
cat("CLUSTER", i, "\n")
cat("Top 10 words: \n")
print(head(sort(km$centers[i, ], decreasing = TRUE), n = 10))
cat("\n")
}
###### question 3 #####
cosine <- function(a,b){
numer <- apply(a * t(b), 2, sum)
denom <- sqrt(sum(a ^2) * sqrt(apply(b^2, 1, sum)))
return(numer / denom)
}
doc.cosine <- cosine(doc.dtm.mat[155, ], doc.dtm.mat)
top5 <-  sort(doc.cosine, decreasing = TRUE)[1:5]
row.names(top5)
row.names(top5)
colnames(top5)
rownames(top5)
row.names(top5)
sort(doc.cosine, decreasing = TRUE)[1:5]
names(top5)
doc$country[names(top5)]
as.numeric(names(top5))
doc$country[as.numeric(names(top5))]
names(top5) <- doc$country[as.numeric(names(top5))]
top5
year <- seq(from = 1960, to = 2010, by = 10)
consine.mean <- rep(NA,length(year)-1)
for(i in 1:length(year)-1){
consine.mean[i] <- mean(doc$cosine[doc$year >= year[i] & doc$year < year[i+1]])
}
consine.mean
plot(year[-1], consine.mean,type = "l", col = "blue",
xlim = c(1970, 2010), ylim = c(0.5, 0.8),
xlab = "year", ylab = "consine")
doc$consine <- doc.cosine
year <- seq(from = 1960, to = 2010, by = 10)
consine.mean <- rep(NA,length(year)-1)
for(i in 1:length(year)-1){
consine.mean[i] <- mean(doc$cosine[doc$year >= year[i] & doc$year < year[i+1]])
}
consine.mean
plot(year[-1], consine.mean,type = "l", col = "blue",
xlim = c(1970, 2010), ylim = c(0.5, 0.8),
xlab = "year", ylab = "consine")
n <- nrow(doc)
doc.mat <- matrix(0, nrow = n, ncol = n)
colnames(doc.mat) <- rownames(doc.mat) <- doc$country
for(i in 1:nrow(doc)){
cosine.i <- cosine(doc.dtm.mat[i, ], doc.dtm.mat)
cosine.i[doc$year > doc$year[i]] <- 0
doc.mat[i,] <- cosine.i
}
doc.mat
library("igraph")
doc.adj <- graph.adjacency(doc.mat, mode = "directed",
diag = FALSE)
plot(doc.adj,vertex.size = 10)
country <- c(unique(trade$country1),unique(trade$country2))
trade <- read.csv("Datasets/trade.csv")
summary(trade)
#### question 1 ####
country <- c(unique(trade$country1),unique(trade$country2))
country <- unique(country)
n <- length(country)
n
trade.mat <- matrix(0, nrow = n, ncol = n)
colnames(trade.mat) <- rownames(trade.mat) <- country
for(i in 1:nrow(trade)){
trade.mat[trade$country1[i], trade$country2[i]] <-  1
if(is.na(trade$exports[i])){
trade.mat[trade$country1[i], trade$country2[i]] <-  0
}
}
